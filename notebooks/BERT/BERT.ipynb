{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "still-fellowship",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from argparse import Namespace\n",
    "from collections import defaultdict, Counter\n",
    "import onmt\n",
    "from onmt.inputters.inputter import _load_vocab, _build_fields_vocab, get_fields, IterOnDevice\n",
    "from onmt.inputters.corpus import ParallelCorpus\n",
    "from onmt.inputters.dynamic_iterator import DynamicDatasetIter\n",
    "from onmt.translate import GNMTGlobalScorer, Translator, TranslationBuilder\n",
    "from onmt.utils.misc import set_random_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "virtual-samuel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<RootLogger root (INFO)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from onmt.utils.logging import init_logger, logger\n",
    "init_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "center-covering",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "set_random_seed(1111, is_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "active-leonard",
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_config = \"\"\"\n",
    "# src_vocab_size: 30000\n",
    "# tgt_vocab_size: 30000\n",
    "\n",
    "save_data: run/samples\n",
    "src_vocab: vocabs/vocab.en\n",
    "tgt_vocab: vocabs/vocab.hu\n",
    "\n",
    "# Corpus opts:\n",
    "data:\n",
    "    hunglish:\n",
    "        path_src: /home1/hu-nmt/hu-nmt/data/ftp.mokk.bme.hu/Hunglish2/combined-en-hu/hunglish2-short-no-qoutes-train.en\n",
    "        path_tgt: /home1/hu-nmt/hu-nmt/data/ftp.mokk.bme.hu/Hunglish2/combined-en-hu/hunglish2-short-no-qoutes-train.hu\n",
    "        transforms: [sentencepiece]\n",
    "        weight: 1\n",
    "    valid:\n",
    "        path_src: /home1/hu-nmt/hu-nmt/data/ftp.mokk.bme.hu/Hunglish2/combined-en-hu/hunglish2-short-no-qoutes-valid.en\n",
    "        path_tgt: /home1/hu-nmt/hu-nmt/data/ftp.mokk.bme.hu/Hunglish2/combined-en-hu/hunglish2-short-no-qoutes-valid.hu\n",
    "        transforms: [sentencepiece]\n",
    "\n",
    "#### Subword\n",
    "src_subword_model: /home1/hu-nmt/hu-nmt/opennmt/experiments-en-hu/sp_models/bpe_en.model\n",
    "tgt_subword_model: /home1/hu-nmt/hu-nmt/opennmt/experiments-en-hu/sp_models/bpe_hu.model\n",
    "src_subword_nbest: 1\n",
    "src_subword_alpha: 0.0\n",
    "tgt_subword_nbest: 1\n",
    "tgt_subword_alpha: 0.0\n",
    "\n",
    "src_seq_length: 16  # maximum source sequence length\n",
    "tgt_seq_length: 16  # maximum target sequence length\n",
    "\n",
    "# TRAIN\n",
    "\n",
    "# Train on a single GPU\n",
    "world_size: 1\n",
    "gpu_ranks: [0]\n",
    "\n",
    "# Batching\n",
    "batch_size: 96\n",
    "#queue_size: 16\n",
    "#accum_count: [3]\n",
    "\n",
    "# General opts\n",
    "save_model: run/model_no_qoutes\n",
    "keep_checkpoint: 10\n",
    "save_checkpoint_steps: 10000\n",
    "average_decay: 0.0005\n",
    "seed: 1234\n",
    "report_every: 100\n",
    "train_steps: 400000\n",
    "valid_steps: 10000 \n",
    "single_pass: False\n",
    "early_stopping: 5 \n",
    "early_stopping_criteria: ppl\n",
    "\n",
    "# Optimization\n",
    "model_dtype: \"fp16\"\n",
    "optim: \"adam\"\n",
    "learning_rate: 2.0\n",
    "warmup_steps: 8000\n",
    "decay_method: \"noam\"\n",
    "adam_beta2: 0.998\n",
    "max_grad_norm: 0\n",
    "label_smoothing: 0.1\n",
    "param_init: 0\n",
    "param_init_glorot: true\n",
    "normalization: \"tokens\"\n",
    "\n",
    "# Model\n",
    "encoder_type: transformer\n",
    "decoder_type: transformer\n",
    "enc_layers: 2\n",
    "dec_layers: 2\n",
    "heads: 8\n",
    "rnn_size: 512\n",
    "word_vec_size: 512\n",
    "transformer_ff: 2048\n",
    "dropout_steps: [0]\n",
    "dropout: [0.1]\n",
    "attention_dropout: [0.1]\n",
    "#share_decoder_embeddings: true\n",
    "\n",
    "# Logging\n",
    "log_file: run/logs_no_qoutes\n",
    "\"\"\"\n",
    "config = yaml.safe_load(yaml_config)\n",
    "with open(\"config.yaml\", \"w\") as f:\n",
    "    f.write(yaml_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "located-resistance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from onmt.utils.parse import ArgumentParser\n",
    "parser = ArgumentParser(description='build_vocab.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "unable-annex",
   "metadata": {},
   "outputs": [],
   "source": [
    "from onmt.opts import dynamic_prepare_opts\n",
    "dynamic_prepare_opts(parser, build_vocab_only=True) #build_vocab_only=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "honest-mount",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_args = ([\"-config\", \"config.yaml\", \"-n_sample\", \"100000\"])\n",
    "opts, unknown = parser.parse_known_args(base_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "plastic-hormone",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(config='config.yaml', data=\"{'hunglish': {'path_src': '/home1/hu-nmt/hu-nmt/data/ftp.mokk.bme.hu/Hunglish2/combined-en-hu/hunglish2-short-no-qoutes-train.en', 'path_tgt': '/home1/hu-nmt/hu-nmt/data/ftp.mokk.bme.hu/Hunglish2/combined-en-hu/hunglish2-short-no-qoutes-train.hu', 'transforms': ['sentencepiece'], 'weight': 1}, 'valid': {'path_src': '/home1/hu-nmt/hu-nmt/data/ftp.mokk.bme.hu/Hunglish2/combined-en-hu/hunglish2-short-no-qoutes-valid.en', 'path_tgt': '/home1/hu-nmt/hu-nmt/data/ftp.mokk.bme.hu/Hunglish2/combined-en-hu/hunglish2-short-no-qoutes-valid.hu', 'transforms': ['sentencepiece']}}\", dump_samples=False, insert_ratio=0.0, mask_length='subword', mask_ratio=0.0, n_sample=100000, num_threads=1, overwrite=False, permute_sent_ratio=0.0, poisson_lambda=3.0, random_ratio=0.0, replace_length=-1, rotate_ratio=0.0, save_config=None, save_data='run/samples', seed=1234, share_vocab=False, skip_empty_level='warning', src_onmttok_kwargs=\"{'mode': 'none'}\", src_seq_length=16, src_subword_alpha=0.0, src_subword_model='/home1/hu-nmt/hu-nmt/opennmt/experiments-en-hu/sp_models/bpe_en.model', src_subword_nbest=1, src_subword_type='none', src_subword_vocab='', src_vocab='vocabs/vocab.en', src_vocab_threshold=0, switchout_temperature=1.0, tgt_onmttok_kwargs=\"{'mode': 'none'}\", tgt_seq_length=16, tgt_subword_alpha=0.0, tgt_subword_model='/home1/hu-nmt/hu-nmt/opennmt/experiments-en-hu/sp_models/bpe_hu.model', tgt_subword_nbest=1, tgt_subword_type='none', tgt_subword_vocab='', tgt_vocab='vocabs/vocab.hu', tgt_vocab_threshold=0, tokendrop_temperature=1.0, tokenmask_temperature=1.0, transforms=[], vocab_sample_queue_size=20)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "separate-printer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-04-03 18:27:34,583 INFO] Parsed 2 corpora from -data.\n",
      "[2021-04-03 18:27:34,631 INFO] Counter vocab from 100000 samples.\n",
      "[2021-04-03 18:27:34,633 INFO] Build vocab on 100000 transformed examples/corpus.\n",
      "[2021-04-03 18:27:34,703 INFO] hunglish's transforms: TransformPipe(SentencePieceTransform(share_vocab=False, src_subword_model=/home1/hu-nmt/hu-nmt/opennmt/experiments-en-hu/sp_models/bpe_en.model, tgt_subword_model=/home1/hu-nmt/hu-nmt/opennmt/experiments-en-hu/sp_models/bpe_hu.model, src_subword_alpha=0.0, tgt_subword_alpha=0.0, src_subword_vocab=, tgt_subword_vocab=, src_vocab_threshold=0, tgt_vocab_threshold=0, src_subword_nbest=1, tgt_subword_nbest=1))\n",
      "[2021-04-03 18:27:34,709 INFO] Loading ParallelCorpus(/home1/hu-nmt/hu-nmt/data/ftp.mokk.bme.hu/Hunglish2/combined-en-hu/hunglish2-short-no-qoutes-train.en, /home1/hu-nmt/hu-nmt/data/ftp.mokk.bme.hu/Hunglish2/combined-en-hu/hunglish2-short-no-qoutes-train.hu, align=None)...\n",
      "[2021-04-03 18:27:39,347 WARNING] Empty line exists in hunglish#48717.\n",
      "[2021-04-03 18:27:44,299 INFO] Counters src:22550\n",
      "[2021-04-03 18:27:44,301 INFO] Counters tgt:25364\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "path vocabs/vocab.en exists, stop.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-b504e8326b24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0monmt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_vocab_main\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbuild_vocab_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/nmt38/lib/python3.8/site-packages/onmt/bin/build_vocab.py\u001b[0m in \u001b[0;36mbuild_vocab_main\u001b[0;34m(opts)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0msave_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_counter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0msave_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_counter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0msave_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_counter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtgt_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nmt38/lib/python3.8/site-packages/onmt/bin/build_vocab.py\u001b[0m in \u001b[0;36msave_counter\u001b[0;34m(counter, save_path)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mcheck_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtok\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcounter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nmt38/lib/python3.8/site-packages/onmt/utils/misc.py\u001b[0m in \u001b[0;36mcheck_path\u001b[0;34m(path, exist_ok, log)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"path {path} exists, may overwrite...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"path {path} exists, stop.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: path vocabs/vocab.en exists, stop."
     ]
    }
   ],
   "source": [
    "from onmt.bin.build_vocab import build_vocab_main\n",
    "build_vocab_main(opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "brave-shield",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab_path = opts.src_vocab\n",
    "tgt_vocab_path = opts.tgt_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "retained-syria",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-04-03 18:27:47,667 INFO] Loading src vocabulary from vocabs/vocab.en\n",
      "[2021-04-03 18:27:47,780 INFO] Loaded src vocab has 22550 tokens.\n",
      "[2021-04-03 18:27:47,803 INFO] Loading tgt vocabulary from vocabs/vocab.hu\n",
      "[2021-04-03 18:27:47,868 INFO] Loaded tgt vocab has 25364 tokens.\n"
     ]
    }
   ],
   "source": [
    "counters = defaultdict(Counter)\n",
    "# load source vocab\n",
    "_src_vocab, _src_vocab_size = _load_vocab(\n",
    "    src_vocab_path,\n",
    "    'src',\n",
    "    counters)\n",
    "# load target vocab\n",
    "_tgt_vocab, _tgt_vocab_size = _load_vocab(\n",
    "    tgt_vocab_path,\n",
    "    'tgt',\n",
    "    counters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "removed-delicious",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize fields\n",
    "src_nfeats, tgt_nfeats = 0, 0 # do not support word features for now\n",
    "fields = get_fields(\n",
    "    'text', src_nfeats, tgt_nfeats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "surprised-strength",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'src': <onmt.inputters.text_dataset.TextMultiField at 0x7fa323c7ee50>,\n",
       " 'tgt': <onmt.inputters.text_dataset.TextMultiField at 0x7fa323c2aa00>,\n",
       " 'indices': <torchtext.data.field.Field at 0x7fa323c2ab80>}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ignored-estonia",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-04-03 18:27:50,861 INFO]  * tgt vocab size: 25368.\n",
      "[2021-04-03 18:27:50,898 INFO]  * src vocab size: 22552.\n"
     ]
    }
   ],
   "source": [
    "# build fields vocab\n",
    "share_vocab = False\n",
    "vocab_size_multiple = 1\n",
    "src_vocab_size = 30000\n",
    "tgt_vocab_size = 30000\n",
    "src_words_min_frequency = 1\n",
    "tgt_words_min_frequency = 1\n",
    "vocab_fields = _build_fields_vocab(\n",
    "    fields, counters, 'text', share_vocab,\n",
    "    vocab_size_multiple,\n",
    "    src_vocab_size, src_words_min_frequency,\n",
    "    tgt_vocab_size, tgt_words_min_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "humanitarian-creativity",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_text_field = vocab_fields[\"src\"].base_field\n",
    "src_vocab = src_text_field.vocab\n",
    "src_padding = src_vocab.stoi[src_text_field.pad_token]\n",
    "\n",
    "tgt_text_field = vocab_fields['tgt'].base_field\n",
    "tgt_vocab = tgt_text_field.vocab\n",
    "tgt_padding = tgt_vocab.stoi[tgt_text_field.pad_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "upper-turkey",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size = 100\n",
    "rnn_size = 500\n",
    "# Specify the core model.\n",
    "\n",
    "encoder_embeddings = onmt.modules.Embeddings(emb_size, len(src_vocab),\n",
    "                                             word_padding_idx=src_padding)\n",
    "\n",
    "encoder = onmt.encoders.RNNEncoder(hidden_size=rnn_size, num_layers=1,\n",
    "                                   rnn_type=\"LSTM\", bidirectional=True,\n",
    "                                   embeddings=encoder_embeddings)\n",
    "\n",
    "decoder_embeddings = onmt.modules.Embeddings(emb_size, len(tgt_vocab),\n",
    "                                             word_padding_idx=tgt_padding)\n",
    "decoder = onmt.decoders.decoder.InputFeedRNNDecoder(\n",
    "    hidden_size=rnn_size, num_layers=1, bidirectional_encoder=True, \n",
    "    rnn_type=\"LSTM\", embeddings=decoder_embeddings)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = onmt.models.model.NMTModel(encoder, decoder)\n",
    "model.to(device)\n",
    "\n",
    "# Specify the tgt word generator and loss computation module\n",
    "model.generator = nn.Sequential(\n",
    "    nn.Linear(rnn_size, len(tgt_vocab)),\n",
    "    nn.LogSoftmax(dim=-1)).to(device)\n",
    "\n",
    "loss = onmt.utils.loss.NMTLossCompute(\n",
    "    criterion=nn.NLLLoss(ignore_index=tgt_padding, reduction=\"sum\"),\n",
    "    generator=model.generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "thrown-performance",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1\n",
    "torch_optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "optim = onmt.utils.optimizers.Optimizer(\n",
    "    torch_optimizer, learning_rate=lr, max_grad_norm=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "pacific-champion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home1/hu-nmt/hu-nmt/data/ftp.mokk.bme.hu/Hunglish2/combined-en-hu/hunglish2-short-no-qoutes-train.en'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opts.data['hunglish']['path_src']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "supreme-shock",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_train = opts.data['hunglish']['path_src']\n",
    "tgt_train =opts.data['hunglish']['path_tgt']\n",
    "src_val = opts.data['valid']['path_src']\n",
    "tgt_val = opts.data['valid']['path_tgt']\n",
    "\n",
    "# build the ParallelCorpus\n",
    "corpus = ParallelCorpus(\"corpus\", src_train, tgt_train)\n",
    "valid = ParallelCorpus(\"valid\", src_val, tgt_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "independent-description",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece\n",
    "\n",
    "# build the training iterator\n",
    "train_iter = DynamicDatasetIter(\n",
    "    corpora={\"corpus\": corpus},\n",
    "    corpora_info={\"corpus\": {\"weight\": 1}},\n",
    "    transforms={sentencepiece},\n",
    "    fields=vocab_fields,\n",
    "    is_train=True,\n",
    "    batch_type=\"sents\",\n",
    "    batch_size=8,\n",
    "    batch_size_multiple=1,\n",
    "    data_type=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "crucial-dictionary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure the iteration happens on GPU 0 (-1 for CPU, N for GPU N)\n",
    "train_iter = iter(IterOnDevice(train_iter, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "humanitarian-franchise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the validation iterator\n",
    "valid_iter = DynamicDatasetIter(\n",
    "    corpora={\"valid\": valid},\n",
    "    corpora_info={\"valid\": {\"weight\": 1}},\n",
    "    transforms={},\n",
    "    fields=vocab_fields,\n",
    "    is_train=False,\n",
    "    batch_type=\"tokens\",\n",
    "    batch_size=8*16,\n",
    "    batch_size_multiple=1,\n",
    "    data_type=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "announced-antenna",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_iter = IterOnDevice(valid_iter, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-isolation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-04-03 18:28:01,021 INFO] Start training loop and validate every 50 steps...\n",
      "[2021-04-03 18:28:01,023 INFO] corpus's transforms: TransformPipe()\n",
      "[2021-04-03 18:28:01,025 INFO] Loading ParallelCorpus(/home1/hu-nmt/hu-nmt/data/ftp.mokk.bme.hu/Hunglish2/combined-en-hu/hunglish2-short-no-qoutes-train.en, /home1/hu-nmt/hu-nmt/data/ftp.mokk.bme.hu/Hunglish2/combined-en-hu/hunglish2-short-no-qoutes-train.hu, align=None)...\n"
     ]
    }
   ],
   "source": [
    "report_manager = onmt.utils.ReportMgr(\n",
    "    report_every=10, start_time=None, tensorboard_writer=None)\n",
    "\n",
    "trainer = onmt.Trainer(model=model,\n",
    "                       train_loss=loss,\n",
    "                       valid_loss=loss,\n",
    "                       optim=optim,\n",
    "                       report_manager=report_manager,\n",
    "                       dropout=[0.1])\n",
    "\n",
    "trainer.train(train_iter=train_iter,\n",
    "              train_steps=100,\n",
    "              valid_iter=valid_iter,\n",
    "              valid_steps=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-floating",
   "metadata": {},
   "source": [
    "# Translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-seattle",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
